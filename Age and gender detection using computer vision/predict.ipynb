{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "JS9YgRkMLone"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "NdjMX72IL3PZ"
   },
   "outputs": [],
   "source": [
    "# Input image\n",
    "image = cv2.imread('./Inputs/input2.jpg')\n",
    "image = cv2.resize(image, (720, 640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "5MxRCn12L5ID"
   },
   "outputs": [],
   "source": [
    "# Importing Models and set mean values\n",
    "face1 = \"./models/opencv_face_detector.pbtxt\"\n",
    "face2 = \"./models/opencv_face_detector_uint8.pb\"\n",
    "age1 = \"./models/age_deploy.prototxt\"\n",
    "age2 = \"./models/age_net.caffemodel\"\n",
    "gen1 = \"./models/gender_deploy.prototxt\"\n",
    "gen2 = \"./models/gender_net.caffemodel\"\n",
    "\n",
    "MODEL_MEAN_VALUES = (78.4263377603, 87.7689143744, 114.895847746)\n",
    "\n",
    "# Using models\n",
    "# Face\n",
    "face = cv2.dnn.readNet(face2, face1)\n",
    "\n",
    "# age\n",
    "age = cv2.dnn.readNet(age2, age1)\n",
    "\n",
    "# gender\n",
    "gen = cv2.dnn.readNet(gen2, gen1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "KwIIYVz1L6Z_"
   },
   "outputs": [],
   "source": [
    "# Categories of distribution\n",
    "la = ['(0-2)', '(4-6)', '(8-12)', '(15-20)',\n",
    "      '(25-32)', '(38-43)', '(48-53)', '(60-100)']\n",
    "lg = ['Male', 'Female']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WGKS8UYoL7kL"
   },
   "outputs": [],
   "source": [
    "# Copy image\n",
    "fr_cv = image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_2SZwTwnL8tw"
   },
   "outputs": [],
   "source": [
    "# Face detection\n",
    "fr_h = fr_cv.shape[0]\n",
    "fr_w = fr_cv.shape[1]\n",
    "blob = cv2.dnn.blobFromImage(fr_cv, 1.0, (300, 300),\n",
    "                             [104, 117, 123], True, False)\n",
    "\n",
    "face.setInput(blob)\n",
    "detections = face.forward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oVmTmkxbL9t1",
    "outputId": "f44931b7-e014-4887-905c-0458bc691e81"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[237, 157, 362, 285]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Face bounding box creation\n",
    "faceBoxes = []\n",
    "for i in range(detections.shape[2]):\n",
    "\n",
    "    #Bounding box creation if confidence > 0.7\n",
    "    confidence = detections[0, 0, i, 2]\n",
    "    if confidence > 0.7:\n",
    "\n",
    "        x1 = int(detections[0, 0, i, 3]*fr_w)\n",
    "        y1 = int(detections[0, 0, i, 4]*fr_h)\n",
    "        x2 = int(detections[0, 0, i, 5]*fr_w)\n",
    "        y2 = int(detections[0, 0, i, 6]*fr_h)\n",
    "\n",
    "        faceBoxes.append([x1, y1, x2, y2])\n",
    "\n",
    "        cv2.rectangle(fr_cv, (x1, y1), (x2, y2),\n",
    "                      (0, 255, 0), int(round(fr_h/150)), 8)\n",
    "\n",
    "faceBoxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 548
    },
    "id": "oyoR3HtaL-8W",
    "outputId": "a2b605d9-02cb-4866-a80f-2cda7e6c9e38"
   },
   "outputs": [],
   "source": [
    "# Checking if face detected or not\n",
    "if not faceBoxes:\n",
    "    print(\"No face detected\")\n",
    "\n",
    "# Final results (otherwise)\n",
    "# Loop for all the faces detected\n",
    "for faceBox in faceBoxes:\n",
    "\n",
    "    #Extracting face as per the faceBox\n",
    "    face = fr_cv[max(0, faceBox[1]-15):\n",
    "                 min(faceBox[3]+15, fr_cv.shape[0]-1),\n",
    "                 max(0, faceBox[0]-15):min(faceBox[2]+15,\n",
    "                               fr_cv.shape[1]-1)]\n",
    "\n",
    "    #Extracting the main blob part\n",
    "    blob = cv2.dnn.blobFromImage(\n",
    "        face, 1.0, (227, 227), MODEL_MEAN_VALUES, swapRB=False)\n",
    "\n",
    "    #Prediction of gender\n",
    "    gen.setInput(blob)\n",
    "    genderPreds = gen.forward()\n",
    "    gender = lg[genderPreds[0].argmax()]\n",
    "\n",
    "    #Prediction of age\n",
    "    age.setInput(blob)\n",
    "    agePreds = age.forward()\n",
    "    age = la[agePreds[0].argmax()]\n",
    "\n",
    "    #Putting text of age and gender\n",
    "    #At the top of box\n",
    "    cv2.putText(fr_cv,\n",
    "                f'{gender}, {age}',\n",
    "                (faceBox[0]-150, faceBox[1]+10),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                1.3,\n",
    "                (217, 0, 0),\n",
    "                4,\n",
    "                cv2.LINE_AA)\n",
    "\n",
    "    plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(fr_cv)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
